{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a51b026-642a-4de8-8945-35654584d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02b245b4-b54c-434b-b883-4168fd901a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "\n",
    "stopwords_path = 'dataset/stopword-id.csv'\n",
    "acronym_path = 'dataset/acronym.csv'\n",
    "out_dir = \"docs\"\n",
    "\n",
    "# Actual news data. Suit your need\n",
    "csv_path = \"../data/final_merge_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a2c1ffa-a46c-4fec-804d-3a6873f86186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stopwords\n",
    "stopwords_df = pd.read_csv(stopwords_path, header=None)\n",
    "custom_stopwords = stopwords_df[0].tolist()\n",
    "custom_stopwords +=['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya']\n",
    "\n",
    "# Load acronyms and build replacement dictionary\n",
    "df_acronym = pd.read_csv(acronym_path)\n",
    "acronym_dict = dict(zip(df_acronym[\"acronym\"], df_acronym[\"expansion\"]))\n",
    "acronym_pattern = re.compile(r'\\b(' + '|'.join(map(re.escape, acronym_dict.keys())) + r')\\b')\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = str(text)\n",
    "    \n",
    "    # Replace acronyms\n",
    "    text = acronym_pattern.sub(lambda match: acronym_dict[match.group(0)], text)\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove HTML image tags\n",
    "    text = re.sub(r'<img[^>]*>', '', text)\n",
    "    \n",
    "    # Remove mentions, URLs, numbers\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Clean punctuation and excess whitespace\n",
    "    text = text.replace(\"b'\", \"\").replace(\"-\", \" \")\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove specific unwanted terms\n",
    "    text = text.replace(\"img\", \"\").replace(\"src\", \"\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4d21625-7f04-44bf-8103-7c1747b062fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV into DataFrame\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20385450-da09-4b7c-9d4f-66f80c1b2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESS\n",
    "\n",
    "df[\"preprocessed_text\"] = df[\"Judul\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85c690fa-1189-4b25-97bf-2f494a333760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VECTORIZE\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=custom_stopwords, max_features=1000)\n",
    "vec = vectorizer.fit_transform(df['preprocessed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "affa2fea-3e49-4ee9-8be4-fbc0917aa8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80472, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "973376d3-3410-4ddf-846b-13022db700f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing shard 0: vectors 0..8387 -> vectors_000.f32 (8388 vectors)\n",
      "Writing shard 1: vectors 8388..16775 -> vectors_001.f32 (8388 vectors)\n",
      "Writing shard 2: vectors 16776..25163 -> vectors_002.f32 (8388 vectors)\n",
      "Writing shard 3: vectors 25164..33551 -> vectors_003.f32 (8388 vectors)\n",
      "Writing shard 4: vectors 33552..41939 -> vectors_004.f32 (8388 vectors)\n",
      "Writing shard 5: vectors 41940..50327 -> vectors_005.f32 (8388 vectors)\n",
      "Writing shard 6: vectors 50328..58715 -> vectors_006.f32 (8388 vectors)\n",
      "Writing shard 7: vectors 58716..67103 -> vectors_007.f32 (8388 vectors)\n",
      "Writing shard 8: vectors 67104..75491 -> vectors_008.f32 (8388 vectors)\n",
      "Writing shard 9: vectors 75492..80471 -> vectors_009.f32 (4980 vectors)\n",
      "Done. Manifest saved to out/manifest.json\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "N, DIM = vec.shape\n",
    "BYTES_PER_VEC = DIM * 4\n",
    "TARGET_SHARD_BYTES = 32 * 1024 * 1024  # 32 MB target\n",
    "vecs_per_shard = max(1, TARGET_SHARD_BYTES // BYTES_PER_VEC)\n",
    "\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "manifest = {\n",
    "    \"total_vectors\": int(N),\n",
    "    \"dim\": int(DIM),\n",
    "    \"dtype\": \"float32\",\n",
    "    \"header_size\": 16,\n",
    "    \"shards\": []\n",
    "}\n",
    "\n",
    "def write_header(f, num_vectors, dim, dtype_code=1):\n",
    "    # magic + num_vectors + dim + dtype_code, all little-endian uint32\n",
    "    f.write(b'VECT')  # 4 bytes\n",
    "    f.write(np.uint32(num_vectors).tobytes())\n",
    "    f.write(np.uint32(dim).tobytes())\n",
    "    f.write(np.uint32(dtype_code).tobytes())\n",
    "\n",
    "start = 0\n",
    "shard_idx = 0\n",
    "while start < N:\n",
    "    end = min(N, start + vecs_per_shard)\n",
    "    count = end - start\n",
    "    shard_name = f\"vectors_{shard_idx:03d}.f32\"\n",
    "    shard_path = os.path.join(out_dir, shard_name)\n",
    "    print(f\"Writing shard {shard_idx}: vectors {start}..{end-1} -> {shard_name} ({count} vectors)\")\n",
    "    with open(shard_path, \"wb\") as f:\n",
    "        write_header(f, count, DIM, dtype_code=1)\n",
    "        # Convert only this slice to dense float32 (row-wise)\n",
    "        # For memory safety, do it in smaller sub-batches if needed\n",
    "        batch_size = 1024  # adjust if your memory is tight\n",
    "        for bstart in range(start, end, batch_size):\n",
    "            bend = min(end, bstart + batch_size)\n",
    "            dense = vec[bstart:bend].toarray().astype(np.float32)\n",
    "            f.write(dense.tobytes(order='C'))\n",
    "    shard_info = {\n",
    "        \"shard\": shard_name,\n",
    "        \"url\": f\"/static/{shard_name}\",  # set as you will serve it\n",
    "        \"start_index\": int(start),\n",
    "        \"count\": int(count),\n",
    "        \"size_bytes\": os.path.getsize(shard_path)\n",
    "    }\n",
    "    manifest[\"shards\"].append(shard_info)\n",
    "    start = end\n",
    "    shard_idx += 1\n",
    "\n",
    "manifest_path = os.path.join(out_dir, \"manifest.json\")\n",
    "with open(manifest_path, \"w\", encoding=\"utf-8\") as mf:\n",
    "    json.dump(manifest, mf, indent=2)\n",
    "\n",
    "print(\"Done. Manifest saved to\", manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d0ffc-e27f-4753-a988-2b7b31b37e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
